\section{Background}

\subsection{Truncated Mixture Model}\label{sec:model}
Before describing the model, we establish the notations used in this paper. We use bold font to represent vectors, any generic element in $\mathbb{R}^d$ is represented by $\vec{x}$.

The density of a balanced mixture of two different Gaussians with parameters $\left(\vec{\mu}_1,\vec{\Sigma}_1\right)$ and  $\left(\vec{\mu}_2,\vec{\Sigma}_2\right)$ respectively, is given by
$f(\vec{x}) := \dfrac{1}{2}\mathcal{N}(\vec{x};\vec{\mu}_1,\vec{\Sigma}_1)+\frac{1}{2}\mathcal{N}(\vec{x};\vec{\mu}_2,\vec{\Sigma}_2),$ where $\mathcal{N}(\vec{x};\vec{\mu},\Sigma) := \dfrac{\exp(-\frac{1}{2}(\vec{x}-\vec{\mu})^T\Sigma^{-1}(\vec{x}-\vec{\mu}))}{(2\pi)^{\frac{d}{2}}\det(\Sigma)^{1/2}}$. For this work we consider the case when true covariances are known and they are equal to $\vec{\Sigma}$. The means are assumed to be symmetric around the origin and we represent the true parameters of the distribution to be $\left(-\vec{\mu},\vec{\Sigma}\right)$ and $\left(\vec{\mu},\vec{\Sigma}\right)$.

Thus, we can write the density as follows:
\begin{align}\label{eq:density_simple}
f_{\vec{\mu}}(\vec{x}) := \dfrac{1}{2}\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+\frac{1}{2}\mathcal{N}(\vec{x};\vec{\mu},\vec{\Sigma}),
\end{align}

Under this setting we consider a truncation set $S \subset \mathbb{R}^d$, which means that we have access only to the samples that fall in the set $S$ which is of positive measure under the true distribution, i.e., \[\int_{\mathbb{R}^d} (0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma}))\mathbf{1}_{S}d\vec{x}= \alpha > 0,\] where $\mathbf{1}_{S}$ is the indicator function for $S$, i.e., if $\vec{x} \in S$ then $\mathbf{1}_{S}(\vec{x})=1$ and is zero otherwise.

Hence we can write the truncated mixture density as follows:
\begin{align}
f_{\vec{\mu},S}(\vec{x})={
	\begin{cases}
	\dfrac{0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+0.5\mathcal{N}(\vec{x};\vec{\mu},\vec{\Sigma})}{\int_{S}0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+0.5\mathcal{N}(\vec{x};\vec{\mu},\vec{\Sigma}) d\vec{x}} \;\;, \vec{x} \in S\\
	0                                              \qquad\qquad\qquad\qquad\qquad\quad\qquad\qquad\qquad\;, \vec{x} \notin S
	\end{cases}
}
\end{align}

The above definition can be generalized for ``truncation" \textit{functions} too. Let $S : \mathbb{R}^d \to \mathbb{R}$ be a non-negative, bounded by one, measurable function so that $0< \alpha = \int_{\mathbb{R}^d} S(\vec{x}) f_{\vec{\mu}}(\vec{x})d\vec{x}$ (we say nonnegative function $S$ is of ``positive measure" if $S(\vec{x})$ is \textit{not} almost everywhere zero). The truncated mixture then is defined as follows:
\[f_{\vec{\mu},S}(\vec{x})= \dfrac{(0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+0.5\mathcal{N}(\vec{x};\vec{\mu},\vec{\Sigma}))S(\vec{x})}{\int_{\mathbb{R}^d}(0.5\mathcal{N}(\vec{x};-\vec{\mu},\vec{\Sigma})+0.5\mathcal{N}(\vec{x};\vec{\mu},\vec{\Sigma}))S(\vec{x}) d\vec{x}}
\]
One can think of $S(\vec{x})$ as the probability to actually see sample $\vec{x}$.
\begin{remark}[Results proven for truncation functions]
Our main Theorems \ref{thm:single} and \ref{thm:multi} provided in the introduction, hold in the general setting where we have non-negative truncation functions $S(\vec{x})$ of ``positive measure". Our proofs are written in the general setting (not only the case of indicator functions).
\end{remark}

We will use the following short hand for the truncated EM density with means $\vec{\mu}$ and truncation set or function $S$ such that
$f_{\vec{\mu},S}(\vec{x})=\dfrac{f_{\vec{\mu}}(\vec{x}) \mathbf{1}_{S}}{\int_{\mathbb{R}^d} f_{\vec{\mu}}(\vec{x})\mathbf{1}_S d\vec{x}}$ or $f_{\vec{\mu},S}(\vec{x})=\dfrac{f_{\vec{\mu}}(\vec{x}) S(\vec{x})}{\int_{\mathbb{R}^d}f_{\vec{\mu}}(\vec{x})S(\vec{x})d\vec{x}}$. Also, we will denote the expected value with respect to the truncated mixture distribution with parameters $-\vec{\lambda}$ and $\vec{\lambda}$ by $\EE_{\vec{\lambda},S}\left[.\right]$.
We conclude the subsection with an important definition that will be needed for the multi-dimensional case.
\begin{definition}[Rotation invariant/Symmetric] We call a ``truncation" function $S(\vec{x})$ rotation invariant if $S(Q\vec{x}) = S(\vec{x})$ for all orthogonal matrices $Q$. It is clear that every rotation invariant ``truncation" function is also even (choose $Q = - \vec{I}$, where $\vec{I}$ denotes the identity matrix). A set $S$ is called rotation invariant if $\mathbf{1}_{S}$ is rotation invariant function and moreover it is called symmetric if $\mathbf{1}_{S}$ is an even function.
\end{definition}

Next, we derive the EM-update rule to estimate the mean under the ``truncated" setting.

\subsection{EM Algorithm}
The EM algorithm tries to maximize a lower bound of the likelihood at every time step. The population version of the update rule to estimate the mean of a truncated balanced Gaussian mixture with symmetric means $(-\vec{\mu},\vec{\mu)}$ and covariance $\vec{\Sigma}$ with truncation set $S$ boils down to:

\begin{align}\label{eq:EM-rule}
	h(\vec{\lambda}_t,\vec{\lambda}):=\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\vec{\Sigma}^{-1}\right]-\EE_{\vec{\lambda},S}\left[\vec{x}^T\vec{\Sigma}^{-1}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]
\end{align}
such that
\begin{align}\label{eq:dyn}
		\vec{\lambda}_{t+1}=\left\{\vec{\lambda}:h(\vec{\lambda}_t,\vec{\lambda})=\vec{0}\right\}.
\end{align}	
The above population EM update rule for the truncated setting was derived in  \cite{Nagarajan and Panageas}. Although the authors were able to analyze the stability of fixed points of the update rule, it is computationally challenging to compute the update rule at every step (especially in higher dimensions) as it accommodates only an implicit form. Thus we use a ``gradient" version of the above rule that is more amenable to analysis and that allows us to easily compute the parameters at every step. We describe the rule below:

\begin{align}\label{eq:grad-EM-rule}
\vec{\lambda}_{t+1}=\vec{\lambda}_{t}+\eta\left(\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\vec{\Sigma}^{-1}\right]-\EE_{\vec{\lambda}_{t},S}\left[\vec{x}^T\vec{\Sigma}^{-1}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_{t})\right]\right)
\end{align}
, where $\eta > 0$ is the step size. 

\begin{comment}
\begin{remark}[Even function $S(\vec{x})$, Symmetric set $S$]
	When the truncation function $S$ is even or the truncation set $S$ is symmetric, we can show (Appendix \ref{app:symtrunc-set}) that the EM update rule accommodates a simpler form, given by:
		\begin{align}
			h(\vec{\lambda}_t,\vec{\lambda}):=\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\vec{\Sigma}^{-1}\right]-\vec{\lambda}^T\vec{\Sigma}^{-1}
		\end{align}
		and
		\begin{align}
			\vec{\lambda}_{t+1}=\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}\right].
		\end{align}
	
\end{remark}
\end{comment}

\begin{remark}[Fixed Points]
There are at least 3 fixed point of the dynamical system given in equation (\ref{eq:dyn}) namely,  $\vec{\mu}$,$-\vec{\mu}$ and $\vec{0}$ as seen in \cite{Nagarajan and Panageas}. We can see that any fixed point of equation \ref{eq:grad-EM-rule} is also a fixed point of equation \ref{eq:EM-rule} and vice versa. In addition, the local stability analysis follows from \cite{Nagarajan and Panageas}.
%\begin{align}
% h(\vec{\mu},\vec{\mu})=\vec{0},\;\;h(-\vec{\mu},-\vec{\mu})=\vec{0} \;\;\textit{and}\;\; h(\vec{0},\vec{0})=\vec{0}
% \end{align}
%In general there may be more fixed points in the dynamics for any arbitrary truncation function $S(\vec{x})$ or set $S$ (see Section \ref{sec:more}). However, in the single dimension case we prove that there are only three fixed points (see Lemma \ref{lem:threefixedpoints}). In multi-dimensional ($d>1$) case we can also show that if $S$ is rotation invariant, then there are only three fixed points as well (see Lemma \ref{lem:symrotation}).
\end{remark}







