\section{Properties of the EM Update Rule}\label{sec:EMalgo}
In the section we analyze the dynamical system arising from the EM update rule. To this end, we first describe the derivative $\nabla_{\vec{\lambda}_t} \vec{\lambda}_{t+1}$ of the dynamical system, by invoking the \textit{Implicit Function Theorem}. Then we present some derivatives that are essential to characterize the dynamics and argue about the stability of fixed points.

\subsection{Properties of the Dynamics}
We use the \textit{Implicit Function Theorem} to represent the derivative of $\vec{\lambda}_{t+1}$ with respect to $\vec{\lambda}_t$ to analyze the dynamical system around some point say $\vec{\gamma}$.

\begin{flalign}\label{eqn:multi-ratio}
	\nabla_{\vec{\lambda}_t}\vec{\lambda}_{t+1} \Big\vert_{\vec{\gamma}}=\nabla_{\vec{\lambda}_{t+1}}\EE_{\vec{\lambda}_{t+1},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_{t+1})\right]^{-1} \Big\vert_{\vec{\gamma}}
	\cdot\nabla_{\vec{\lambda}_t}\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\right]\Big\vert_{\vec{\gamma}}
\end{flalign}

The analogue of the above ratio in the single dimension setting is given by:

\begin{align}\label{eqn:single-ratio}
	\frac{d \lambda_{t+1}}{d \lambda_t}\Big\vert_{\vec{\gamma}}=\frac{\frac{d}{d \lambda_t}\EE_{\mu,S}\left[x\tanh\left(\frac{x\lambda_t}{\sigma^2}\right)\right]\Big\vert_{\lambda_t=\gamma}}{\frac{d}{d \lambda_{t+1}}\EE_{\lambda_{t+1},S}\left[x\tanh\left(\frac{x\lambda_{t+1}}{\sigma^2}\right)\right]\Big\vert_{\lambda_t=\gamma}}
\end{align}


To this end, we state the following lemma which describes certain derivatives of the terms involved in the above ratio to argue about local stability of the fixed points.

\begin{lemma}[Some Useful Derivatives]\label{lem:derivatives}
The following equations hold:
\begin{enumerate}	
 \item
 $\begin{aligned}[t]
	\nabla_{\vec{\lambda}} \EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]&=\vec{\Sigma}^{-1}\EE_{\vec{\lambda},S}\left[\vec{x}\vec{x}^T\right]-\\
	&\vec{\Sigma}^{-1}\EE_{\vec{\lambda},S}\left[\vec{x}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]\EE_{\vec{\lambda},S}\left[\vec{x}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]^T
\end{aligned}$

\item
$\begin{aligned}[t]
	\nabla_{\vec{\mu}} \EE_{\vec{\mu},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]=\vec{\Sigma}^{-1}\EE_{\vec{\mu},S}\left[\vec{x}\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\mu})\right]\\
	\hspace{1in}-\vec{\Sigma}^{-1}\EE_{\vec{\mu},S}\left[\vec{x}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]\EE_{\vec{\mu},S}\left[\vec{x}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\mu})\right]^T
\end{aligned}$

\item $\begin{aligned}[t]
	\nabla_{\vec{\lambda}} \EE_{\vec{\mu},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]&=\vec{\Sigma}^{-1}\EE_{\vec{\mu},S}\left[\vec{x}\vec{x}^T\frac{1}{\cosh^2(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})}\right]\\
	&=\vec{\Sigma}^{-1}\EE_{\vec{\mu},S}\left[\vec{x}\vec{x}^T\left(1-\tanh^2(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right)\right]
\end{aligned}$

\end{enumerate}
\end{lemma}


\subsection{Two Important Lemmas}
We end the section about the update rule of EM by proving that is well-defined (in the sense that for every $\lambda_t$ there exists a \textit{unique} $\vec{\lambda}_{t+1}$) and moreover, we show that the update rule has Jacobian that is invertible for all $\vec{x} \in \mathbb{R}^d$.
The first Lemma that is needed to argue about global convergence (in case there are three fixed points), with the use of center-stable manifold (as the proof appears in \cite{LPPSJR17}) is the following:
\begin{lemma}[Local Diffeomorphism]\label{lem:localdiff} Let $J$ be the Jacobian of the update rule of the EM dynamics (of size $d \times d$). It holds that $J$ is invertible.
\end{lemma}
\begin{proof}
	
	It suffices to prove that $	\nabla_{\vec{\lambda}} \EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right], 	\nabla_{\vec{\lambda}} \EE_{\vec{\mu},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]$ have non zero eigenvalues (thus invertible) for all $\vec{\lambda} \in \mathbb{R}^d$ and hence the result follows by Equation (\ref{eqn:multi-ratio}).
	Observe that
	\begin{align*}
		M:= \mathbb{E}_{\vec{\lambda},S}[\vec{x}\vec{x}^T(1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda}))] &= Cov\left(\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}, \vec{x}\sqrt{1 -\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}\right) \\&+ \mathbb{E}_{\vec{\lambda},S}[\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}]\mathbb{E}_{\vec{\lambda},S}[\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}]^T
	\end{align*}
	(where $\vec{x}$ follows a truncated mixture with parameters $\vec{\lambda}, \vec{\Sigma}$ and truncated function $S$ of ``positive measure") which is positive definite (not positive semidefinite) since the function $S$ is of ``positive measure" and $-1<\tanh(y)< 1$ for all $y \in \mathbb{R}$ (otherwise the variables $\vec{x}_1,...,\vec{x}_d$ would live in a lower dimensional subspace). Moreover, from Lemma \ref{lem:derivatives} it is clear that
	\begin{align*}
		\vec{\Sigma} \nabla_{\vec{\lambda}} \EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right] - M &= Cov\left(\vec{x}\tanh(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda}), \vec{x}\tanh(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})\right),
	\end{align*}
	which is positive definite as well. Hence we conclude that $$\vec{\Sigma} \cdot \nabla_{\vec{\lambda}} \EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]$$ is positive definite, thus
	$\nabla_{\vec{\lambda}}\EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]$ is invertible.
	The proof for \\$\nabla_{\vec{\lambda}} \EE_{\vec{\mu},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]$ is simpler since
	\begin{align*}
		\vec{\Sigma} \nabla_{\vec{\lambda}} \EE_{\vec{\mu},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right] &= Cov\left(\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}, \vec{x}\sqrt{1 -\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}\right)
		\\&+\mathbb{E}_{\vec{\mu},S}[\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}]\mathbb{E}_{\vec{\mu},S}[\vec{x}\sqrt{1-\tanh^2(\vec{x}^T \vec{\Sigma}^{-1}\vec{\lambda})}]^T,
	\end{align*}
	(where $\vec{x}$ follows a truncated mixture with parameters $\vec{\mu}, \vec{\Sigma}$ and truncated function $S$ of ``positive measure").
	
\end{proof}	

The second lemma is about the fact that the update rule of EM is well defined.
\begin{lemma}[Well defined]\label{lem:welldefined} Let $\lambda_t \in \mathbb{R}^d$. There exists a unique $\vec{\lambda'}$ such that
\[
\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\vec{\Sigma}^{-1}\right]=\EE_{\vec{\lambda'},S}\left[\vec{x}^T\vec{\Sigma}^{-1}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda'})\right].
\]
\end{lemma}

\begin{proof}
	
	Let $H(\vec{w}) = \vec{\Sigma}\EE_{\vec{w},S}\left[\vec{x}^T\vec{\Sigma}^{-1}\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{w})\right]$. In the Lemma \ref{lem:localdiff} we showed that $\nabla_{\vec{w}}  H(\vec{w})$ is positive definite since $S$ is of positive measure.
	Assume there exist $\lambda, \tilde{\lambda}$ so that $H(\vec{\lambda}) = H(\vec{\tilde{\lambda}})$. Let $\vec{y}_t = t \vec{\lambda} + (1-t) \vec{\tilde{\lambda}}$ for $t \in [0,1]$. Using standard techniques from calculus and that $\nabla_{\vec{w}}  H(\vec{w})$ is symmetric we get that
	\begin{equation}
		(\vec{\lambda} - \vec{\tilde{\lambda}})^T (H(\vec{\lambda}) - H(\vec{\tilde{\lambda}})) \geq \min_{t \in [0,1]}\lambda_{\min} (\nabla_{\vec{w}}  H(\vec{w}) \big\vert_{\vec{w} = \vec{y}_t}) \norm{\vec{\lambda} - \vec{\tilde{\lambda}}}^2,
	\end{equation}
	where $\lambda_{\min}(A)$ denotes the minimum eigenvalue of matrix $A$. It is clear that the left hand side is zero, and also the matrix $\nabla_{\vec{w}}  H(\vec{w}) \big\vert_{\vec{w} = \vec{y}_t}$ has all its eigenvalues positive for every $t \in [0,1]$ (using the fact that $\nabla_{\vec{w}}  H(\vec{w})$ is positive definite for all $w$ from the proof of Lemma \ref{lem:localdiff} above). We conclude that $\vec{\lambda} = \vec{\tilde{\lambda}}$.
	
\end{proof}

\begin{remark} In this remark, we would like to argue why there is always a $\vec{\lambda}_{t+1}$ such that \[
\EE_{\vec{\mu},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_t)\vec{x}^T\vec{\Sigma}^{-1}\right]=\EE_{\vec{\lambda}_{t+1},S}\left[\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda}_{t+1})\vec{x}^T\vec{\Sigma}^{-1}\right].
\]
The reason is that $\vec{\lambda}_{t+1}$ is chosen to maximize a particular quantity. If the gradient of that quantity has no roots, it means that $\norm{\vec{\lambda}_{t+1}}_2$ should be infinity. But the quantity is a concave function (in the proof of Lemma \ref{lem:localdiff} we showed that $- \nabla_{\vec{\lambda}} \EE_{\vec{\lambda},S}\left[\vec{x}^T\tanh(\vec{x}^T\vec{\Sigma}^{-1}\vec{\lambda})\right]\vec{\Sigma}^{-1}$ is negative definite which is the Hessian of the quantity to be maximized), so the maximum should be attained in the interior (i.e., $\lambda_{t+1}$ cannot have $\ell_2$ norm infinity).
\end{remark}
